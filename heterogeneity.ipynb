{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneity Assessments\n",
    "### Sarah M. McDonald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# paths\n",
    "folder = r\"\"\n",
    "hex01_path = f\"{folder}/heterogeneity/DC_LC_hex01.dbf\"\n",
    "hex1_path = f\"{folder}/heterogeneity/DC_LC_hex1.dbf\"\n",
    "accuracy_table_path = f\"{folder}/fuzzy_TA/summary_tables/DC_fuzzy3x3_tables.xlsx\"\n",
    "points_path = f\"{folder}/lcc_aa_points_cleaned.gpkg\"\n",
    "hex_grid_paths = f\"{folder}/heterogeneity/DC_hexagons.gpkg\"\n",
    "excel_path = f\"{folder}/heterogeneity/DC_heterogeneity_accuracy.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in hex results and clean up data\n",
    "def clean_up(path, all_classes:bool=True):\n",
    "    df = (\n",
    "        gpd.read_file(path)\n",
    "        .drop(['geometry'], axis=1)\n",
    "    )\n",
    "\n",
    "    if all_classes:\n",
    "        # compute % per class\n",
    "        cols = {\n",
    "            1   : \"Water\",\n",
    "            2   : \"Wetlands\",\n",
    "            3   : \"Tree Canopy\",\n",
    "            4   : \"Shrubland\",\n",
    "            5   : \"Low Vegetation\",\n",
    "            6   : \"Barren\",\n",
    "            7   : \"Structures\",\n",
    "            8   : \"Other Impervious\",\n",
    "            9   : \"Roads\",\n",
    "            10  : \"TC Over Structures\",\n",
    "            11  : \"TC Over Other Imp\",\n",
    "            12  : \"TC Over Roads\",\n",
    "        }\n",
    "\n",
    "        # compute % class\n",
    "        df.loc[:, 'total'] = df[[f\"VALUE_{x}\" for x in cols]].sum(axis=1)\n",
    "        df = df.query(\"total > 0\")\n",
    "\n",
    "        for c in cols:\n",
    "            df.loc[:, f\"{cols[c]}\"] = df[f\"VALUE_{c}\"] / df['total']\n",
    "            df.loc[:, f\"H_{c}\"] = np.log(df[f\"{cols[c]}\"]) * df[f\"{cols[c]}\"]\n",
    "\n",
    "        # compute shannon's diveristy index\n",
    "        df.loc[:, 'H'] = df[[f\"H_{i}\" for i in cols.keys()]].sum(axis=1) * -1\n",
    "\n",
    "        # calculate shannon's equitability index EH \n",
    "        df.loc[:, 'EH'] = df['H'] / np.log(len(cols))\n",
    "\n",
    "        # col order\n",
    "        c = ['GRID_ID', 'total'] + list(cols.values()) + ['H', 'EH']\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # compute % per class\n",
    "        cols = {\n",
    "            \"Water\": [1],\n",
    "            \"Herbaceous\" : [2,4,5],\n",
    "            \"Tree Canopy\" : [3, 10, 11, 12],\n",
    "            \"Barren\" : [6],\n",
    "            \"Impervious\" : [7, 8, 9],\n",
    "        }\n",
    "\n",
    "        # compute % class\n",
    "        df.loc[:, 'total'] = df[[x for x in list(df) if 'VALUE_' in x]].sum(axis=1)\n",
    "        df = df.query(\"total > 0\")\n",
    "\n",
    "        for c in cols:\n",
    "            df.loc[:, c] = df[[f\"VALUE_{i}\" for i in cols[c]]].sum(axis=1) / df['total']\n",
    "            df.loc[:, f\"H_{c}\"] = np.log(df[c]) * df[c]\n",
    "\n",
    "        # compute shannon's diveristy index\n",
    "        df.loc[:, 'H'] = df[[f\"H_{i}\" for i in cols.keys()]].sum(axis=1) * -1\n",
    "\n",
    "        # calculate shannon's equitability index EH \n",
    "        df.loc[:, 'EH'] = df['H'] / np.log(len(cols))\n",
    "\n",
    "        # col order\n",
    "        c = ['GRID_ID', 'total'] + list(cols.keys()) + ['H', 'EH']\n",
    "\n",
    "    # return data\n",
    "    return df[c]\n",
    "\n",
    "# call and print df\n",
    "hex1 = clean_up(hex1_path)\n",
    "hex01 = clean_up(hex01_path)\n",
    "hex1_5 = clean_up(hex1_path, all_classes=False)\n",
    "hex01_5 = clean_up(hex01_path, all_classes=False)\n",
    "\n",
    "hex1.to_excel(excel_path, sheet_name=\"hex1_shannon\", index=False)\n",
    "book = load_workbook(excel_path)\n",
    "writer = pd.ExcelWriter(excel_path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "hex1_5.to_excel(writer, sheet_name=\"hex1_LC5_shannon\", index=False)\n",
    "hex01.to_excel(writer, sheet_name=\"hex01_shannon\", index=False)\n",
    "hex01_5.to_excel(writer, sheet_name=\"hex01_LC5_shannon\", index=False)\n",
    "writer.close()\n",
    "\n",
    "# read in points sjoin with grid\n",
    "points = (\n",
    "    gpd.read_file(points_path, layer='AA_clean')\n",
    "    .filter(items=['uid', 'geometry'])\n",
    "    .rename(columns={'uid':'point_uid'})\n",
    ")\n",
    "hex1_gdf = (\n",
    "    gpd.read_file(hex_grid_paths, layer='hex1')\n",
    "    .filter(items=['GRID_ID', 'uid', 'geometry'])\n",
    ")\n",
    "hex1_sj = (\n",
    "    gpd.sjoin(hex1_gdf[['GRID_ID','uid','geometry']], points)\n",
    "    .filter(items=['GRID_ID', 'uid', 'point_uid'])\n",
    ")\n",
    "hex01_gdf = (\n",
    "    gpd.read_file(hex_grid_paths, layer='hex01')\n",
    "    .filter(items=['GRID_ID', 'uid', 'geometry'])   \n",
    ")\n",
    "hex01_sj = (\n",
    "    gpd.sjoin(hex01_gdf[['GRID_ID', 'uid', 'geometry']], points)\n",
    "    .filter(items=['GRID_ID', 'uid', 'point_uid'])\n",
    ")\n",
    "\n",
    "# merge data to grids \n",
    "hex1_gdf = (\n",
    "    hex1_gdf\n",
    "    .merge(hex1[['GRID_ID', 'total', 'H', 'EH']], on='GRID_ID', how='left')\n",
    "    .merge(hex1_5[['GRID_ID', 'H', 'EH']].rename(columns={'H':\"H5\", 'EH':\"EH5\"}), on='GRID_ID', how='left')\n",
    ")\n",
    "\n",
    "hex01_gdf = (\n",
    "    hex01_gdf\n",
    "    .merge(hex01[['GRID_ID', 'total', 'H', 'EH']], on='GRID_ID', how='left')\n",
    "    .merge(hex01_5[['GRID_ID', 'H', 'EH']].rename(columns={'H':\"H5\", 'EH':\"EH5\"}), on='GRID_ID', how='left')\n",
    ")\n",
    "\n",
    "# read aa data and merge to points\n",
    "aa_df = (\n",
    "    pd.read_excel(accuracy_table_path, sheet_name='all_data')\n",
    "    .filter(items=['uid', 'GT_static', 'Map_static', 'GT_st_3x3'])\n",
    ")\n",
    "aa_df.loc[:, 'GT_st'] = False\n",
    "aa_df.loc[aa_df['GT_static']==aa_df['Map_static'], 'GT_st'] = True\n",
    "aa_df = aa_df[['uid', 'GT_st', 'GT_st_3x3']]\n",
    "points = (\n",
    "    points\n",
    "    .merge(aa_df, left_on='point_uid', right_on='uid')\n",
    "    .drop('uid', axis=1)\n",
    "    .merge(hex1_sj[['GRID_ID', 'point_uid']].rename(columns={'GRID_ID':'hex1_grid'}), on='point_uid', how='left')\n",
    "    .merge(hex01_sj[['GRID_ID', 'point_uid']].rename(columns={'GRID_ID':'hex01_grid'}), on='point_uid', how='left')\n",
    ")\n",
    " \n",
    "# count number of points per grid, number of correct points per grid, and calculate % correct per grid\n",
    "h1_counts = (\n",
    "    (\n",
    "    points\n",
    "    .groupby('hex1_grid')\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0:\"hex1_numPts\"})\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            points\n",
    "            .query(\"GT_st\")\n",
    "            .groupby('hex1_grid')\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0:\"hex1_numPtsT\"})\n",
    "        ),\n",
    "        on='hex1_grid',\n",
    "        how='outer'\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            points\n",
    "            .query(\"GT_st_3x3\")\n",
    "            .groupby('hex1_grid')\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0:\"hex1_numPtsT3x3\"})\n",
    "        ),\n",
    "        on='hex1_grid',\n",
    "        how='outer'\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "h1_counts.loc[:, 'hex1_pcTrue'] = h1_counts['hex1_numPtsT'] / h1_counts['hex1_numPts']\n",
    "h1_counts.loc[:, 'hex1_pcTrue3x3'] = h1_counts['hex1_numPtsT3x3'] / h1_counts['hex1_numPts']\n",
    "h1_counts = h1_counts[['hex1_grid', 'hex1_numPts', 'hex1_pcTrue', 'hex1_pcTrue3x3']]\n",
    "hex1_gdf = (\n",
    "    hex1_gdf\n",
    "    .merge(\n",
    "        h1_counts,\n",
    "        left_on='GRID_ID',\n",
    "        right_on='hex1_grid',\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "# hex1_gdf.to_file(hex_grid_paths, layer='hex1', driver=\"GPKG\")\n",
    "\n",
    "# count number of points per grid, number of correct points per grid, and calculate % correct per grid\n",
    "h01_counts = (\n",
    "    (\n",
    "    points\n",
    "    .groupby('hex01_grid')\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns={0:\"hex01_numPts\"})\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            points\n",
    "            .query(\"GT_st\")\n",
    "            .groupby('hex01_grid')\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0:\"hex01_numPtsT\"})\n",
    "        ),\n",
    "        on='hex01_grid',\n",
    "        how='outer'\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            points\n",
    "            .query(\"GT_st_3x3\")\n",
    "            .groupby('hex01_grid')\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0:\"hex01_numPtsT3x3\"})\n",
    "        ),\n",
    "        on='hex01_grid',\n",
    "        how='outer'\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "h01_counts.loc[:, 'hex01_pcTrue'] = h01_counts['hex01_numPtsT'] / h01_counts['hex01_numPts']\n",
    "h01_counts.loc[:, 'hex01_pcTrue3x3'] = h01_counts['hex01_numPtsT3x3'] / h01_counts['hex01_numPts']\n",
    "h01_counts = h01_counts[['hex01_grid', 'hex01_numPts', 'hex01_pcTrue', 'hex01_pcTrue3x3']]\n",
    "hex01_gdf = (\n",
    "    hex01_gdf\n",
    "    .merge(\n",
    "        h01_counts,\n",
    "        left_on='GRID_ID',\n",
    "        right_on='hex01_grid',\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "# hex01_gdf.to_file(hex_grid_paths, layer='hex01', driver=\"GPKG\")\n",
    "points = (\n",
    "    points\n",
    "    .merge(\n",
    "        (\n",
    "            hex1_gdf\n",
    "            .filter(items=['GRID_ID', 'H', 'EH', 'H5', 'EH5'], axis=1)\n",
    "            .rename(columns={'H':'H_hex1', 'EH':'EH_hex1', 'H5':'H5_hex1', 'EH5':'EH5_hex1'})\n",
    "        ), \n",
    "        left_on='hex1_grid', \n",
    "        right_on='GRID_ID'\n",
    "    )\n",
    "    .drop('GRID_ID', axis=1)\n",
    "    .merge(\n",
    "        (\n",
    "            hex01_gdf\n",
    "            .filter(items=['GRID_ID', 'H', 'EH', 'H5', 'EH5'], axis=1)\n",
    "            .rename(columns={'H':'H_hex01', 'EH':'EH_hex01', 'H5':'H5_hex01', 'EH5':'EH5_hex01'})\n",
    "        ), \n",
    "        left_on='hex01_grid', \n",
    "        right_on='GRID_ID'\n",
    "    )\n",
    "    .drop(['GRID_ID', 'geometry'], axis=1)\n",
    ")\n",
    "\n",
    "book = load_workbook(excel_path)\n",
    "writer = pd.ExcelWriter(excel_path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "points.to_excel(writer, sheet_name=\"all_data\", index=False)\n",
    "hex1_gdf.drop('geometry', axis=1).to_excel(writer, sheet_name=\"hex1_summary\", index=False)\n",
    "hex01_gdf.drop('geometry', axis=1).to_excel(writer, sheet_name=\"hex01_summary\", index=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# ta files\n",
    "ta_folder = f\"{folder}/heterogeneity/RegionGroup/TA\"\n",
    "ta_files = os.listdir(ta_folder)\n",
    "\n",
    "# iterate files paths, read them, and aggregate over hex id and region group values\n",
    "data = {}\n",
    "for ta in ta_files:\n",
    "    data[ta] = (\n",
    "        pd.read_csv(f\"{ta_folder}/{ta}\")\n",
    "        .groupby(['uid', 'RegionID'])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .query(\"uid > 0\")\n",
    "        .query(\"RegionID > 0\")\n",
    "    )\n",
    "\n",
    "# land cover names per value\n",
    "lc = {\n",
    "    1   : \"Water\",\n",
    "    2   : \"Wetlands\",\n",
    "    3   : \"Tree Canopy\",\n",
    "    4   : \"Shrubland\",\n",
    "    5   : \"Low Vegetation\",\n",
    "    6   : \"Barren\",\n",
    "    7   : \"Structures\",\n",
    "    8   : \"Other Impervious\",\n",
    "    9   : \"Roads\",\n",
    "    10  : \"TC Over Structures\",\n",
    "    11  : \"TC Over Other Impervious\",\n",
    "    12  : \"TC Over Roads\",\n",
    "}\n",
    "\n",
    "lc5 = {\n",
    "    1   : \"Water\",\n",
    "    3   : \"Tree Canopy\",\n",
    "    4   : \"Herbaceous\",\n",
    "    6   : \"Barren\",\n",
    "    7   : \"Impervious\",\n",
    "}\n",
    "\n",
    "# read in region group crosswalk to id/lc class\n",
    "cw_lc = (\n",
    "    gpd.read_file(f\"{folder}/heterogeneity/RegionGroup/DC_LC_regionGroup8.tif.vat.dbf\")\n",
    "    .filter(items=['Value', 'LINK'], axis=1)\n",
    "    .rename(columns={'Value':'RegionID', 'LINK':'LC_val'})\n",
    ")\n",
    "for i in lc:\n",
    "    cw_lc.loc[cw_lc['LC_val'] == i, \"LC\"] = lc[i]\n",
    "\n",
    "cw_lc5 = (\n",
    "    gpd.read_file(f\"{folder}/heterogeneity/RegionGroup/DC_LC_5class_regionGroup8.tif.vat.dbf\")\n",
    "    .filter(items=['Value', 'LINK'], axis=1)\n",
    "    .rename(columns={'Value':'RegionID', 'LINK':'LC_val'})\n",
    ")\n",
    "for i in lc5:\n",
    "    cw_lc5.loc[cw_lc5['LC_val'] == i, \"LC\"] = lc5[i]\n",
    "\n",
    "# merge land cover to ta results\n",
    "book = load_workbook(excel_path)\n",
    "writer = pd.ExcelWriter(excel_path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "for ta in data:\n",
    "    if \"5class\" in ta:\n",
    "        data[ta] = (\n",
    "            data[ta]\n",
    "            .merge(cw_lc5, on='RegionID', how='left')\n",
    "        )\n",
    "    else:\n",
    "        data[ta] = (\n",
    "            data[ta]\n",
    "            .merge(cw_lc, on='RegionID', how='left')\n",
    "        )\n",
    "    data[ta].to_excel(writer, sheet_name=ta, index=False)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
