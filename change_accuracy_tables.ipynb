{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pivot tables of change accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "\n",
    "# paths\n",
    "folder = r\"\"\n",
    "cw_path = f\"{folder}/CIC/t1-t3_lc_change_values KEY.csv\"\n",
    "points_path = f\"{folder}/clean_points/lcc_aa_points_cleaned.gpkg\"\n",
    "fuzzy_path = f\"{folder}/clean_points/fuzzy_TA\"\n",
    "write_folder = f\"{folder}/clean_points/change_accuracy\"\n",
    "excel_path = f\"{write_folder}/REGION_changeAA.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosswalk\n",
    "cw = (\n",
    "    pd.read_csv(cw_path)\n",
    "    .drop('SMM_added', axis=1)\n",
    ")\n",
    "\n",
    "# separate gain and loss\n",
    "cw[['loss','gain']] = cw['class'].str.split(' to ', n=1, expand=True)\n",
    "cw.loc[cw['gain'].isna(), 'gain'] = cw.loss\n",
    "\n",
    "#  aggregate classes\n",
    "agg_df = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        data={\n",
    "            'Water'                                     : 'Water',\n",
    "            'Emergent Wetlands'                         : 'Herbaceous',\n",
    "            'Tree Canopy'                               : 'Tree Canopy',\n",
    "            'Shrubland'                                 : 'Herbaceous',\n",
    "            'Low Vegetation'                            : 'Herbaceous',\n",
    "            'Barren'                                    : 'Barren',\n",
    "            'Impervious Structures'                     : \"Impervious\",\n",
    "            'Other Impervious'                          : \"Impervious\",\n",
    "            'Impervious Roads'                          : \"Impervious\",\n",
    "            'Tree Canopy Over Impervious Structures'    : 'Tree Canopy',\n",
    "            'Tree Canopy Over Other Impervious'         : 'Tree Canopy',\n",
    "            'Tree Canopy Over Impervious Roads'         : 'Tree Canopy',\n",
    "\n",
    "        },\n",
    "        orient='index'\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "agg_df.columns = ['lc', 'agg_lc']\n",
    "\n",
    "cw = (\n",
    "    cw\n",
    "    .merge(agg_df, left_on='loss', right_on='lc')\n",
    "    .rename(columns={'agg_lc':\"loss_agg\"})\n",
    "    .drop('lc', axis=1)\n",
    "    .merge(agg_df, left_on='gain', right_on='lc')\n",
    "    .rename(columns={'agg_lc':\"gain_agg\"})\n",
    "    .drop('lc', axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single change table\n",
    "states = ['DC','DE','MD','NY','PA','VA','WV']\n",
    "\n",
    "# read in points\n",
    "points = (\n",
    "    gpd.read_file(points_path, layer='AA_clean')\n",
    "    .filter(items=['uid', 'state', 'type', 'GrndTruth', 'origMap'], axis=1)\n",
    "    .rename(columns={'GrndTruth':'GT_ch_pt', 'origMap':'Map_pt'})\n",
    "    .merge(cw, left_on=\"GT_ch_pt\", right_on='value', how='left')\n",
    "    .drop(['class', 'value', 'loss','gain'], axis=1)\n",
    "    .rename(columns={'loss_agg':'GT_T1_agg', 'gain_agg':'GT_T3_agg'})\n",
    "    .merge(cw, left_on=\"Map_pt\", right_on='value', how='left')\n",
    "    .drop(['class', 'value', 'loss','gain'], axis=1)\n",
    "    .rename(columns={'loss_agg':'Map_T1_agg', 'gain_agg':'Map_T3_agg'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in fuzzy state data and corrections\n",
    "fz_list = []\n",
    "for st in states:\n",
    "    df = (\n",
    "        pd.read_csv(f\"{fuzzy_path}/{st}/lcc/{st}_lcc_TA_3x3.csv\")\n",
    "    )\n",
    "    fz_list.append(df.copy())\n",
    "    df = None\n",
    "\n",
    "# concat data together\n",
    "fuz_df = pd.concat(fz_list)\n",
    "fz_list = None\n",
    "\n",
    "# iterate corrected TAs and replace info for uids in the corrected data\n",
    "corrected = [\n",
    "    f\"{fuzzy_path}/correction/lcc_overlap_TA.csv\",\n",
    "    f\"{fuzzy_path}/correction/lcc_overlap_TA_dc.csv\"\n",
    "]\n",
    "for c in corrected:\n",
    "    #  read in corrections\n",
    "    tmp = pd.read_csv(c)\n",
    "\n",
    "    # get list of corrected ids\n",
    "    uids = tmp.uid.unique().tolist()\n",
    "\n",
    "    # drop incorrect ids and append corrected\n",
    "    fuz_df = (\n",
    "        fuz_df\n",
    "        .query(\"uid not in @uids\")\n",
    "    )\n",
    "    fuz_df = pd.concat([fuz_df, tmp])\n",
    "\n",
    "    tmp = None\n",
    "\n",
    "fuz_df = ( \n",
    "    fuz_df\n",
    "    .query(\"uid >= 0\")\n",
    "    .merge(cw, left_on='lcc', right_on='value', how='left')\n",
    "    .drop(['class', 'value', 'loss','gain',], axis=1) #  'lcc', 'count'\n",
    "    .rename(columns={'loss_agg':'Fzy_T1_agg', 'gain_agg':'Fzy_T3_agg'})\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change or static bsaed on agg classes\n",
    "points.loc[:, 'Map_agg'] = \"Static\"\n",
    "points.loc[points['Map_T1_agg']!=points['Map_T3_agg'], 'Map_agg'] = \"Change\"\n",
    "points.loc[:, 'GT_agg'] = \"Static\"\n",
    "points.loc[points['GT_T1_agg']!=points['GT_T3_agg'], 'GT_agg'] = \"Change\"\n",
    "\n",
    "# change or static based on full schema\n",
    "points.loc[:, 'Map_all'] = \"Static\"\n",
    "points.loc[points['Map_pt']>12, 'Map_all'] = \"Change\"\n",
    "points.loc[:, 'GT_all'] = \"Static\"\n",
    "points.loc[points['GT_ch_pt']>12, 'GT_all'] = \"Change\"\n",
    "\n",
    "# fuzzy - where GT change, did we map change in 3x3 window?\n",
    "points.loc[:, 'Map_agg_fuzzy'] = points['Map_agg']\n",
    "uids_ = points.query(\"Map_agg_fuzzy != GT_agg\").uid.unique().tolist()\n",
    "points = points.set_index(\"uid\")\n",
    "for uid in uids_:\n",
    "    #  gt type\n",
    "    gt = points.loc[uid, 'GT_agg']\n",
    "\n",
    "    # check if uid has same type \n",
    "    if gt == 'Change':\n",
    "        q = \"(uid == @uid) & (Fzy_T1_agg != Fzy_T3_agg)\"\n",
    "        if len(fuz_df.query(q)) > 0:\n",
    "            points.loc[uid, \"Map_agg_fuzzy\"] = gt\n",
    "    else:\n",
    "        q = \"(uid == @uid) & (Fzy_T1_agg == Fzy_T3_agg)\" # no data in lcc ta means no change aka static\n",
    "        if len(fuz_df.query(q)) > 0:\n",
    "            points.loc[uid, \"Map_agg_fuzzy\"] = gt\n",
    "\n",
    "# fuzzy - where GT change, did we map change in 3x3 window?\n",
    "points.loc[:, 'Map_all_fuzzy'] = points['Map_all']\n",
    "uids_ = points.query(\"Map_all_fuzzy != GT_all\").index.unique().tolist()\n",
    "for uid in uids_:\n",
    "    #  gt type\n",
    "    gt = points.loc[uid, 'GT_all']\n",
    "\n",
    "    # check if uid has same type \n",
    "    if gt == 'Change':\n",
    "        q = \"(uid == @uid) & (lcc != 65535) & (lcc > 12)\"\n",
    "        if len(fuz_df.query(q)) > 0:\n",
    "            points.loc[uid, \"Map_all_fuzzy\"] = gt\n",
    "    else:\n",
    "        q = \"(uid == @uid) & ((lcc == 0) | (lcc == 65535) | (lcc < 12))\" # no data in lcc ta means no change aka static\n",
    "        if len(fuz_df.query(q)) > 0:\n",
    "            points.loc[uid, \"Map_all_fuzzy\"] = gt\n",
    "\n",
    "points = points.reset_index()\n",
    "\n",
    "# sum totals and pivot?\n",
    "agg_tot     = pd.pivot(points.groupby([\"Map_agg\", \"GT_agg\"]).size().reset_index(), index='Map_agg', columns='GT_agg', values=0)\n",
    "all_tot     = pd.pivot(points.groupby([\"Map_all\", \"GT_all\"]).size().reset_index(), index='Map_all', columns='GT_all', values=0)\n",
    "agg_tot_fzy = pd.pivot(points.groupby([\"Map_agg_fuzzy\", \"GT_agg\"]).size().reset_index(), index='Map_agg_fuzzy', columns='GT_agg', values=0)\n",
    "all_tot_fzy = pd.pivot(points.groupby([\"Map_all_fuzzy\", \"GT_all\"]).size().reset_index(), index='Map_all_fuzzy', columns='GT_all', values=0)\n",
    "\n",
    "# add fequencies and UA PA numbers\n",
    "def _piv_helper(tmp):\n",
    "    # compute totals\n",
    "    tmp.loc[:, 'frequency'] = tmp.sum(axis=1)\n",
    "    tmp.loc['frequency'] = tmp.sum(axis=0)\n",
    "\n",
    "    # compute PA and UA\n",
    "    diag_sum = 0\n",
    "    for lc in ['Change', 'Static']:\n",
    "        tmp.loc[lc, 'UA'] = tmp.loc[lc, lc] / tmp.loc[lc, 'frequency']\n",
    "        tmp.loc['PA', lc] = tmp.loc[lc, lc] / tmp.loc['frequency', lc]\n",
    "        diag_sum += tmp.loc[lc, lc]\n",
    "\n",
    "    # calculate overall accuracy\n",
    "    tmp.loc['PA', 'UA'] = diag_sum / tmp.loc['frequency', 'frequency']\n",
    "\n",
    "    # return\n",
    "    return tmp\n",
    "\n",
    "agg_tot = _piv_helper(agg_tot)\n",
    "all_tot = _piv_helper(all_tot)\n",
    "agg_tot_fzy = _piv_helper(agg_tot_fzy)\n",
    "all_tot_fzy = _piv_helper(all_tot_fzy)\n",
    "\n",
    "if os.path.isfile(excel_path):\n",
    "    os.remove(excel_path)\n",
    "\n",
    "all_tot.to_excel(excel_path, sheet_name='change', engine='openpyxl')\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n",
    "    agg_tot.to_excel(writer, sheet_name='changeAgg')\n",
    "    all_tot_fzy.to_excel(writer, sheet_name='changeFuzzy')\n",
    "    agg_tot_fzy.to_excel(writer, sheet_name='changeAggFuzzy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pivot(points, query_, out_path, fuz_df=None):\n",
    "    # clean up table\n",
    "    if os.path.isfile(out_path):\n",
    "        os.remove(out_path)\n",
    "\n",
    "    agg_lcs = ['Tree Canopy', 'Impervious', 'Herbaceous', 'Barren', 'Water']\n",
    "    for agg_lc in agg_lcs:\n",
    "\n",
    "        # select points where the lc is present in mapped or GT data\n",
    "        tmp = (\n",
    "            points\n",
    "            .query(query_)\n",
    "            .set_index(\"uid\")\n",
    "        )\n",
    "\n",
    "        # assign change types\n",
    "        tmp.loc[(tmp['GT_T1_agg']==tmp['GT_T3_agg']) & (tmp['GT_T3_agg'] == agg_lc), 'GT_type'] = f'{agg_lc}, No Change' \n",
    "        tmp.loc[(tmp['GT_T1_agg']==tmp['GT_T3_agg']) & (tmp['GT_T3_agg'] != agg_lc), 'GT_type'] = f'Not {agg_lc}, No Change' \n",
    "        tmp.loc[(tmp['GT_T1_agg']!=tmp['GT_T3_agg']) & ((tmp['GT_T1_agg']!=agg_lc) & (tmp['GT_T3_agg']!=agg_lc)), 'GT_type'] = f'Not {agg_lc}, Change' \n",
    "        tmp.loc[(tmp['GT_T1_agg']==agg_lc)&(tmp['GT_type'].isna()), 'GT_type'] = 'Loss'\n",
    "        tmp.loc[(tmp['GT_T3_agg']==agg_lc)&(tmp['GT_type'].isna()), 'GT_type'] = 'Gain'\n",
    "\n",
    "        tmp.loc[(tmp['Map_T1_agg']==tmp['Map_T3_agg']) & (tmp['Map_T3_agg'] == agg_lc), 'Map_type'] = f'{agg_lc}, No Change' \n",
    "        tmp.loc[(tmp['Map_T1_agg']==tmp['Map_T3_agg']) & (tmp['Map_T3_agg'] != agg_lc), 'Map_type'] = f'Not {agg_lc}, No Change' \n",
    "        tmp.loc[(tmp['Map_T1_agg']!=tmp['Map_T3_agg']) & ((tmp['Map_T1_agg']!=agg_lc) & (tmp['Map_T3_agg']!=agg_lc)), 'Map_type'] = f'Not {agg_lc}, Change' \n",
    "        tmp.loc[(tmp['Map_T1_agg']==agg_lc)&(tmp['Map_type'].isna()), 'Map_type'] = 'Loss'\n",
    "        tmp.loc[(tmp['Map_T3_agg']==agg_lc)&(tmp['Map_type'].isna()), 'Map_type'] = 'Gain'\n",
    "\n",
    "        # IF Fuzzy - do this\n",
    "        if fuz_df is not None:\n",
    "            #  iterate where points data disagree, if fuzzy matches GT, update\n",
    "            uids = tmp.query(\"GT_type != Map_type\").index.unique().tolist()\n",
    "            for uid in uids:\n",
    "                # get GT type\n",
    "                gt_type = tmp.loc[uid, 'GT_type']\n",
    "\n",
    "                # check if GT type exists in fuzzy window\n",
    "                # this class should not appear as GT should only be gain or loss\n",
    "                if gt_type in [f'{agg_lc}, No Change', f'Not {agg_lc}, No Change', f'Not {agg_lc}, Change'] :\n",
    "                    print(f\"Error {uid} - {gt_type}\")\n",
    "                elif gt_type == \"Gain\":\n",
    "                    q = \"(uid == @uid) & (Fzy_T1_agg != @agg_lc and Fzy_T3_agg == @agg_lc)\"\n",
    "                    if len(fuz_df.query(q)) > 0:\n",
    "                        tmp.loc[uid, 'Map_type'] = gt_type\n",
    "                elif gt_type == \"Loss\":\n",
    "                    q = \"(uid == @uid) & (Fzy_T1_agg == @agg_lc and Fzy_T3_agg != @agg_lc)\"\n",
    "                    if len(fuz_df.query(q)) > 0:\n",
    "                        tmp.loc[uid, 'Map_type'] = gt_type\n",
    "                else:\n",
    "                    print(f\"{uid} - expected No Change, Gain, Loss, got {gt_type}\")\n",
    "\n",
    "        # get totals\n",
    "        tmp = (\n",
    "            tmp\n",
    "            .groupby(['GT_type', 'Map_type'])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # create pivot table\n",
    "        tmp = pd.pivot(tmp, index='Map_type', columns='GT_type', values=0)\n",
    "\n",
    "        # reorganize to be 1-12 and add missing rows/columns \n",
    "        types = ['Gain', 'Loss', f'{agg_lc}, No Change', f'Not {agg_lc}, No Change', f'Not {agg_lc}, Change']\n",
    "        tmp = tmp.reindex(types, axis=0, fill_value=0)\n",
    "        tmp = tmp.reindex(types, axis=1, fill_value=0)\n",
    "\n",
    "        # compute totals\n",
    "        tmp.loc[:, 'frequency'] = tmp.sum(axis=1)\n",
    "        tmp.loc['frequency'] = tmp.sum(axis=0)\n",
    "\n",
    "        # write data\n",
    "        if not os.path.isfile(out_path):\n",
    "            tmp.to_excel(out_path, sheet_name=agg_lc, engine='openpyxl')\n",
    "        else:\n",
    "            with pd.ExcelWriter(out_path, engine='openpyxl', mode='a') as writer:\n",
    "                tmp.to_excel(writer, sheet_name=agg_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where we mapped change, how accurate?\n",
    "out_path = f\"{write_folder}/REGION_changeAA_commission.xlsx\"\n",
    "query_ = \"(Map_T1_agg == @agg_lc or Map_T3_agg == @agg_lc) and (Map_T1_agg != Map_T3_agg)\"\n",
    "_pivot(points, query_, out_path, fuz_df=None)\n",
    "\n",
    "# Where change is ground truthed, what did we miss?\n",
    "out_path = f\"{write_folder}/REGION_changeAA_omission.xlsx\"\n",
    "query_ = \"(GT_T1_agg == @agg_lc or GT_T3_agg == @agg_lc) and (GT_T1_agg != GT_T3_agg)\"\n",
    "_pivot(points, query_, out_path, fuz_df=None)\n",
    "\n",
    "# Where change is ground truthed, what did we miss?\n",
    "out_path = f\"{write_folder}/REGION_changeAA_omission_fuzzy.xlsx\"\n",
    "query_ = \"(GT_T1_agg == @agg_lc or GT_T3_agg == @agg_lc) and (GT_T1_agg != GT_T3_agg)\"\n",
    "_pivot(points, query_, out_path, fuz_df=fuz_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcc_aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
