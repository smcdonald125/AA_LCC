{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean points\n",
    "### Sarah M. McDonald, smcdonald@chesapeakebay.net\n",
    "This notebook cleans the attributes in the AA point shapefiles provided by the CIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# paths\n",
    "input_folder = r\"\" # path to folder containing the data from CIC\n",
    "output_folder = r\"\" # path to a folder to write the cleaned points\n",
    "change_point_path = f\"{input_folder}/change_matrices/AA_Points_For_Confusion_Matrix/CBW_change.shp\"\n",
    "lcc_crosswalk_path = f\"{input_folder}/t1-t3_lc_change_values KEY.csv\" # NOTE: assumes the static classes are included\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare crosswalk table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in crosswalk\n",
    "cw = pd.read_csv(lcc_crosswalk_path)\n",
    "\n",
    "# separate T1 and T3 LC into unique columns\n",
    "cw[['T1', 'T3']] = cw['class'].str.split(' to ', n=1, expand=True)\n",
    "\n",
    "# copy T1 to T3 for static classes\n",
    "cw.loc[cw['T3'].isna(), 'T3'] = cw.T1\n",
    "\n",
    "# create boolean valid value\n",
    "cw.loc[:, 'validGT'] = True\n",
    "cw.loc[cw['SMM_added']==1, 'validGT'] = False\n",
    "cw = cw.drop('SMM_added', axis=1)\n",
    "\n",
    "# drop columns\n",
    "cw = cw.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read change points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in points\n",
    "gdf = gpd.read_file(change_point_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up Class column - create state, type (change, buffer, static), and class columns (the lcc class used as strata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add DC prefix to make syntax similar to other states\n",
    "gdf.loc[gdf['Class'].str.split('_', n=1, expand=True)[0]=='class', 'Class'] = gdf['Class'].str.replace('class', 'DC_class')\n",
    "\n",
    "# split Class into individual items\n",
    "x = gdf['Class'].str.split('_',  expand=True)\n",
    "\n",
    "# create state column\n",
    "x.loc[:, 'state'] = x[0]\n",
    "x.loc[x['state']=='NCBuff', 'state'] = 'DC' # no change in DC doesn't have DC prefix\n",
    "\n",
    "# merge state back to gdf\n",
    "gdf = gdf.merge(x[['state']], left_index=True, right_index=True)\n",
    "\n",
    "# create point type - change sample, buffer sample, or static sample (no change no buffer)\n",
    "gdf.loc[gdf['Class'].str.contains('buffer'), 'type'] = 'buffer'\n",
    "gdf.loc[gdf['Class'].str.contains('NCBuff'), 'type'] = 'static'\n",
    "gdf.loc[gdf['type'].isna(), 'type'] = 'change'\n",
    "\n",
    "# replace to ensure class_## syntax\n",
    "gdf.loc[:, 'Class'] = gdf['Class'].str.replace('_0_', '_')\n",
    "\n",
    "# retrieve item after class\n",
    "gdf.loc[:,'strata_cls'] = gdf['Class'].str.split(\"class_\", n=1, expand=True)[1].str.split('_', n=1, expand=True)[0]\n",
    "gdf.loc[gdf['strata_cls']=='leftovers', 'strata_cls'] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the T1 and T3 class names to observed/mapped and ground-truthed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mapped T1 and T3 class names\n",
    "gdf = (\n",
    "    gdf\n",
    "    .merge(cw[['value', 'T1', 'T3']], left_on='Classified', right_on='value', how='left')\n",
    "    .rename(columns={\n",
    "        'T1'    : \"T1_mapped\",\n",
    "        'T3'    : \"T3_mapped\",\n",
    "    })\n",
    ")\n",
    "\n",
    "# add ground-truthed T1 and T3 class names\n",
    "gdf = (\n",
    "    gdf\n",
    "    .merge(cw, left_on='GrndTruth', right_on='value', how='left')\n",
    "    .rename(columns={\n",
    "        'T1'    : \"T1_Truth\",\n",
    "        'T3'    : \"T3_Truth\",\n",
    "    })\n",
    ")\n",
    "\n",
    "# add srate class T1 and T3 class names\n",
    "gdf.loc[:, 'strata_cls'] = gdf['strata_cls'].fillna(0)\n",
    "gdf.loc[:, 'strata_cls'] = gdf.strata_cls.str.split('.', n=1, expand=True)[0].fillna(0).astype(int)\n",
    "gdf = (\n",
    "    gdf\n",
    "    .merge(cw[['value', 'T1', 'T3']], left_on='strata_cls', right_on='value', how='left')\n",
    "    .rename(columns={\n",
    "        'T1'    : \"T1_strata\",\n",
    "        'T3'    : \"T3_strata\",\n",
    "    })\n",
    ")\n",
    "\n",
    "# add column showing if class used to stratify points matches mapped\n",
    "gdf.loc[:, 'StrataMatch'] = 'NA'\n",
    "gdf.loc[(gdf['Classified'] == gdf['strata_cls']) & (gdf['type'] == 'change') & (~gdf['Class'].str.contains('leftover')), 'StrataMatch'] = 'True'\n",
    "gdf.loc[(gdf['Classified'] != gdf['strata_cls']) & (gdf['type'] == 'change') & (~gdf['Class'].str.contains('leftover')), 'StrataMatch'] = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder final columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data by state, type\n",
    "gdf = gdf.sort_values(by=['state', 'type', 'strata_cls'])\n",
    "\n",
    "# add unique integer id\n",
    "gdf.loc[:, 'uid'] = [x for x in range(1, len(gdf)+1)]\n",
    "\n",
    "# rename original Class \n",
    "gdf = gdf.rename(columns={'Class':'orig_strata', 'Classified':'origMap'})\n",
    "\n",
    "# reorder columns\n",
    "gdf = gdf[['uid', 'state', 'type', 'strata_cls', 'T1_strata', 'T3_strata', 'T1_mapped', 'T3_mapped', 'T1_Truth', 'T3_Truth', 'StrataMatch', 'orig_strata', 'GrndTruth', 'validGT', 'origMap', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write cleaned data to geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gpkg path\n",
    "path = f\"{output_folder}/lcc_aa_points_cleaned.gpkg\"\n",
    "\n",
    "# write results\n",
    "gdf.to_file(path, layer='AA_clean', driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
